{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e8cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2116a00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_2/constituency_html_dump\\n/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_2/constituency_candidates_data\\n'/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_1/phase1_constituency_list_links_.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_path='/Users/saml16/projects/Elections_info/static/lok_sabha_2024'\n",
    "constituency_list_file_path=static_path+'/constituency_list.csv'\n",
    "phase='/phase_2'\n",
    "constituency_links_file_path=static_path+phase+'/constituency_links_list.csv'\n",
    "constituency_html_file_path=static_path+phase+'/constituency.html'\n",
    "constituency_folder_path=static_path+phase+'/constituency_html_dump/'\n",
    "\n",
    "fetched_constituencies_ids_file_path='/Users/saml16/projects/Elections_info/static/lok_sabha_2024/constituency_list.csv'\n",
    "\n",
    "\"\"\"/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_2/constituency_html_dump\n",
    "/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_2/constituency_candidates_data\n",
    "'/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_1/phase1_constituency_list_links_.csv\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433beef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constituency</th>\n",
       "      <th>constituency_link</th>\n",
       "      <th>state</th>\n",
       "      <th>constituency_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARUNACHAL EAST</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ARUNACHAL PRADESH</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARUNACHAL WEST</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ARUNACHAL PRADESH</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DARRANG-UDALGURI</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIBRUGARH</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>BALURGHAT</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>COOCH BEHAR (SC)</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>DARJEELING</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>JALPAIGURI (SC)</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>RAIGANJ</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    constituency  \\\n",
       "0    ANDAMAN AND NICOBAR ISLANDS   \n",
       "1                 ARUNACHAL EAST   \n",
       "2                 ARUNACHAL WEST   \n",
       "3               DARRANG-UDALGURI   \n",
       "4                      DIBRUGARH   \n",
       "..                           ...   \n",
       "184                    BALURGHAT   \n",
       "185             COOCH BEHAR (SC)   \n",
       "186                   DARJEELING   \n",
       "187              JALPAIGURI (SC)   \n",
       "188                      RAIGANJ   \n",
       "\n",
       "                                     constituency_link  \\\n",
       "0    index.php?action=show_candidates&constituency_...   \n",
       "1    index.php?action=show_candidates&constituency_...   \n",
       "2    index.php?action=show_candidates&constituency_...   \n",
       "3    index.php?action=show_candidates&constituency_...   \n",
       "4    index.php?action=show_candidates&constituency_...   \n",
       "..                                                 ...   \n",
       "184  index.php?action=show_candidates&constituency_...   \n",
       "185  index.php?action=show_candidates&constituency_...   \n",
       "186  index.php?action=show_candidates&constituency_...   \n",
       "187  index.php?action=show_candidates&constituency_...   \n",
       "188  index.php?action=show_candidates&constituency_...   \n",
       "\n",
       "                           state constituency_id  \n",
       "0    ANDAMAN AND NICOBAR ISLANDS             579  \n",
       "1              ARUNACHAL PRADESH              29  \n",
       "2              ARUNACHAL PRADESH              28  \n",
       "3                          ASSAM              35  \n",
       "4                          ASSAM              33  \n",
       "..                           ...             ...  \n",
       "184                  WEST BENGAL             539  \n",
       "185                  WEST BENGAL             534  \n",
       "186                  WEST BENGAL             537  \n",
       "187                  WEST BENGAL             536  \n",
       "188                  WEST BENGAL             538  \n",
       "\n",
       "[189 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the constituency url html\n",
    "def fetch_constituency_links():\n",
    "    \n",
    "    url = 'https://www.myneta.info/LokSabha2024/'\n",
    "    # Part of the href to search for in the links\n",
    "    search_query = 'action=show_candidate'\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find all <a> tags that contain the search query in their href attribute\n",
    "    a_tags = soup.find_all('a', href=lambda href: href and search_query in href)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for a in a_tags:\n",
    "        link_={}\n",
    "        # Get the link text and href\n",
    "        link_['constituency'] = a.text.strip()\n",
    "        link_['constituency_link'] = a.get('href')\n",
    "\n",
    "        # Navigate to the grandparent and find the button\n",
    "        grandparent = a.find_parent().find_parent()\n",
    "        button = grandparent.find('button')\n",
    "        link_['state'] = button.text.strip() if button else \"None\"\n",
    "        link_['constituency_id'] = link_['constituency_link'].split('=')[2] if link_['constituency_link'] else 0\n",
    "\n",
    "        data.append(link_)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "check=fetch_constituency_links()\n",
    "\n",
    "check\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05167007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping for fetched id: 579\n",
      "Skipping for fetched id: 29\n",
      "Skipping for fetched id: 28\n",
      "Skipping for fetched id: 35\n",
      "Skipping for fetched id: 33\n",
      "Skipping for fetched id: 36\n",
      "Skipping for fetched id: 34\n",
      "Skipping for fetched id: 37\n",
      "Skipping for fetched id: 30\n",
      "Skipping for fetched id: 32\n",
      "Skipping for fetched id: 39\n",
      "Skipping for fetched id: 38\n",
      "Skipping for fetched id: 31\n",
      "Skipping for fetched id: 45\n",
      "Skipping for fetched id: 53\n",
      "Skipping for fetched id: 52\n",
      "Skipping for fetched id: 46\n",
      "Skipping for fetched id: 48\n",
      "Skipping for fetched id: 50\n",
      "Skipping for fetched id: 49\n",
      "Skipping for fetched id: 47\n",
      "Done for id: 51\n",
      "Skipping for fetched id: 89\n",
      "Done for id: 92\n",
      "Done for id: 91\n",
      "Done for id: 90\n",
      "Done for id: 156\n",
      "Skipping for fetched id: 155\n",
      "Done for id: 185\n",
      "Done for id: 184\n",
      "Done for id: 183\n",
      "Done for id: 186\n",
      "Done for id: 182\n",
      "Done for id: 187\n",
      "Done for id: 178\n",
      "Done for id: 177\n",
      "Done for id: 176\n",
      "Done for id: 188\n",
      "Done for id: 180\n",
      "Done for id: 181\n",
      "Done for id: 179\n",
      "Done for id: 175\n",
      "Done for id: 220\n",
      "Done for id: 213\n",
      "Done for id: 224\n",
      "Done for id: 215\n",
      "Done for id: 216\n",
      "Done for id: 217\n",
      "Done for id: 206\n",
      "Done for id: 205\n",
      "Done for id: 223\n",
      "Done for id: 218\n",
      "Done for id: 209\n",
      "Done for id: 210\n",
      "Done for id: 221\n",
      "Done for id: 212\n",
      "Done for id: 222\n",
      "Done for id: 211\n",
      "Done for id: 225\n",
      "Done for id: 214\n",
      "Done for id: 207\n",
      "Done for id: 208\n",
      "Skipping for fetched id: 227\n",
      "Skipping for fetched id: 232\n",
      "Skipping for fetched id: 233\n",
      "Done for id: 235\n",
      "Done for id: 239\n",
      "Skipping for fetched id: 230\n",
      "Done for id: 236\n",
      "Skipping for fetched id: 231\n",
      "Done for id: 238\n",
      "Done for id: 237\n",
      "Skipping for fetched id: 229\n",
      "Skipping for fetched id: 228\n",
      "Done for id: 234\n",
      "Done for id: 265\n",
      "Done for id: 266\n",
      "Skipping for fetched id: 261\n",
      "Done for id: 264\n",
      "Skipping for fetched id: 263\n",
      "Skipping for fetched id: 262\n",
      "Done for id: 269\n",
      "Skipping for fetched id: 260\n",
      "Done for id: 270\n",
      "Done for id: 271\n",
      "Skipping for fetched id: 259\n",
      "Done for id: 267\n",
      "Done for id: 268\n",
      "Skipping for fetched id: 310\n",
      "Skipping for fetched id: 311\n",
      "Skipping for fetched id: 312\n",
      "Skipping for fetched id: 313\n",
      "Skipping for fetched id: 314\n",
      "Skipping for fetched id: 315\n",
      "Skipping for fetched id: 338\n",
      "Done for id: 366\n",
      "Skipping for fetched id: 360\n",
      "Done for id: 373\n",
      "Done for id: 370\n",
      "Skipping for fetched id: 361\n",
      "Done for id: 376\n",
      "Skipping for fetched id: 354\n",
      "Done for id: 374\n",
      "Skipping for fetched id: 355\n",
      "Skipping for fetched id: 363\n",
      "Skipping for fetched id: 353\n",
      "Skipping for fetched id: 359\n",
      "Skipping for fetched id: 358\n",
      "Done for id: 371\n",
      "Done for id: 378\n",
      "Skipping for fetched id: 356\n",
      "Done for id: 369\n",
      "Skipping for fetched id: 362\n",
      "Done for id: 377\n",
      "Skipping for fetched id: 364\n",
      "Done for id: 368\n",
      "Done for id: 375\n",
      "Skipping for fetched id: 357\n",
      "Done for id: 365\n",
      "Done for id: 372\n",
      "Skipping for fetched id: 380\n",
      "Skipping for fetched id: 387\n",
      "Skipping for fetched id: 392\n",
      "Skipping for fetched id: 384\n",
      "Skipping for fetched id: 382\n",
      "Skipping for fetched id: 383\n",
      "Skipping for fetched id: 408\n",
      "Skipping for fetched id: 401\n",
      "Skipping for fetched id: 407\n",
      "Skipping for fetched id: 390\n",
      "Skipping for fetched id: 403\n",
      "Skipping for fetched id: 398\n",
      "Skipping for fetched id: 394\n",
      "Skipping for fetched id: 386\n",
      "Skipping for fetched id: 421\n",
      "Skipping for fetched id: 404\n",
      "Skipping for fetched id: 389\n",
      "Skipping for fetched id: 414\n",
      "Skipping for fetched id: 409\n",
      "Skipping for fetched id: 411\n",
      "Skipping for fetched id: 397\n",
      "Skipping for fetched id: 400\n",
      "Skipping for fetched id: 406\n",
      "Skipping for fetched id: 402\n",
      "Skipping for fetched id: 417\n",
      "Skipping for fetched id: 396\n",
      "Skipping for fetched id: 413\n",
      "Skipping for fetched id: 385\n",
      "Skipping for fetched id: 419\n",
      "Skipping for fetched id: 412\n",
      "Skipping for fetched id: 415\n",
      "Skipping for fetched id: 418\n",
      "Skipping for fetched id: 405\n",
      "Skipping for fetched id: 420\n",
      "Skipping for fetched id: 399\n",
      "Skipping for fetched id: 381\n",
      "Skipping for fetched id: 391\n",
      "Skipping for fetched id: 388\n",
      "Skipping for fetched id: 393\n",
      "Skipping for fetched id: 416\n",
      "Done for id: 442\n",
      "Skipping for fetched id: 441\n",
      "Done for id: 463\n",
      "Done for id: 456\n",
      "Done for id: 458\n",
      "Skipping for fetched id: 451\n",
      "Done for id: 461\n",
      "Done for id: 460\n",
      "Done for id: 459\n",
      "Skipping for fetched id: 449\n",
      "Done for id: 464\n",
      "Done for id: 457\n",
      "Skipping for fetched id: 453\n",
      "Skipping for fetched id: 450\n",
      "Skipping for fetched id: 452\n",
      "Skipping for fetched id: 455\n",
      "Skipping for fetched id: 454\n",
      "Skipping for fetched id: 448\n",
      "Skipping for fetched id: 445\n",
      "Skipping for fetched id: 444\n",
      "Skipping for fetched id: 447\n",
      "Skipping for fetched id: 446\n",
      "Skipping for fetched id: 443\n",
      "Skipping for fetched id: 535\n",
      "Done for id: 539\n",
      "Skipping for fetched id: 534\n",
      "Done for id: 537\n",
      "Skipping for fetched id: 536\n",
      "Done for id: 538\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fetch_constituency_html(constituency_ids,output_path):\n",
    " \n",
    "    # remove existing ids. \n",
    "    # fetch html of the constituencies.\n",
    "\n",
    "\n",
    "    fetched_constituencies= pd.read_csv(fetched_constituencies_ids_file_path)\n",
    "    fetched_constituencies_ids=set(fetched_constituencies['constituency_ids'])\n",
    "    \n",
    "    for constituency_id in constituency_ids:\n",
    "        if int(constituency_id) not in fetched_constituencies_ids and int(constituency_id)!=0:\n",
    "            r = requests.get(\"https://www.myneta.info/LokSabha2024/index.php?action=show_candidates&constituency_id=\"+str(constituency_id))\n",
    "            #r.content\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "            name = output_path+str(constituency_id)+\".html\"\n",
    "            with open( name, \"w\", encoding='utf-8') as file :\n",
    "                file.write(str(soup.prettify()))\n",
    "            \n",
    "            fetched_constituencies_ids.add(constituency_id)\n",
    "            \n",
    "            \n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(\"Done for id: \"+ str(constituency_id))\n",
    "        else:\n",
    "            print(\"Skipping for fetched id: \"+ str(constituency_id))\n",
    "        \n",
    "        pd.DataFrame(list(fetched_constituencies_ids),columns=['constituency_ids']).to_csv(fetched_constituencies_ids_file_path,index=False)\n",
    "    \n",
    "\n",
    "fetch_constituency_html(check['constituency_id'],constituency_folder_path)         \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae08ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the constituency list for this pahse \n",
    "check.to_csv(constituency_links_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch users data\n",
    "# fetch users images\n",
    "# sort the data into required formats \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1ad2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests_html\n",
      "  Obtaining dependency information for requests_html from https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in /Users/saml16/anaconda3/lib/python3.11/site-packages (from requests_html) (2.31.0)\n",
      "Collecting pyquery (from requests_html)\n",
      "  Obtaining dependency information for pyquery from https://files.pythonhosted.org/packages/36/b7/f7ccf9e52e2817e1265d3719c600fa4ef33c07de4d5ef0ced3f43ab1cef2/pyquery-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyquery-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fake-useragent (from requests_html)\n",
      "  Obtaining dependency information for fake-useragent from https://files.pythonhosted.org/packages/e4/99/60d8cf1b26938c2e0a57e232f7f15641dfcd6f8deda454d73e4145910ff6/fake_useragent-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting parse (from requests_html)\n",
      "  Obtaining dependency information for parse from https://files.pythonhosted.org/packages/ce/f0/30fe1494f1910ad3ea40639b13ac48cdb16a8600e8861cbfc2c560661ddf/parse-1.20.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading parse-1.20.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: bs4 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from requests_html) (0.0.2)\n",
      "Requirement already satisfied: w3lib in /Users/saml16/anaconda3/lib/python3.11/site-packages (from requests_html) (1.21.0)\n",
      "Collecting pyppeteer>=0.0.14 (from requests_html)\n",
      "  Obtaining dependency information for pyppeteer>=0.0.14 from https://files.pythonhosted.org/packages/3d/ee/fb2757a38025421fd3844a0ed0a230b78c9c04a66355024436cf3005a70c/pyppeteer-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests_html) (2024.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests_html) (6.0.0)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests_html)\n",
      "  Obtaining dependency information for pyee<12.0.0,>=11.0.0 from https://files.pythonhosted.org/packages/16/cc/5cea8a0a0d3deb90b5a0d39ad1a6a1ccaa40a9ea86d793eb8a49d32a6ed0/pyee-11.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests_html) (4.65.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyppeteer>=0.0.14->requests_html) (1.26.16)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests_html)\n",
      "  Obtaining dependency information for websockets<11.0,>=10.0 from https://files.pythonhosted.org/packages/cc/19/2f003f9f81c0fab2eabb81d8fc2fce5fb5b5714f1b4abfe897cb209e031d/websockets-10.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading websockets-10.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from bs4->requests_html) (4.12.2)\n",
      "Requirement already satisfied: lxml>=2.1 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyquery->requests_html) (4.9.3)\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests_html)\n",
      "  Obtaining dependency information for cssselect>=1.2.0 from https://files.pythonhosted.org/packages/06/a9/2da08717a6862c48f1d61ef957a7bba171e7eefa6c0aa0ceb96a140c2a6b/cssselect-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from requests->requests_html) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from requests->requests_html) (3.4)\n",
      "Requirement already satisfied: six>=1.4.1 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from w3lib->requests_html) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/saml16/anaconda3/lib/python3.11/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests_html) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->bs4->requests_html) (2.4)\n",
      "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
      "Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading websockets-10.4-cp311-cp311-macosx_11_0_arm64.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: parse, fake-useragent, websockets, pyee, cssselect, pyquery, pyppeteer, requests_html\n",
      "  Attempting uninstall: cssselect\n",
      "    Found existing installation: cssselect 1.1.0\n",
      "    Uninstalling cssselect-1.1.0:\n",
      "      Successfully uninstalled cssselect-1.1.0\n",
      "Successfully installed cssselect-1.2.0 fake-useragent-1.5.1 parse-1.20.1 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests_html-0.10.0 websockets-10.4\n"
     ]
    }
   ],
   "source": [
    "!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e34a2c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Check if the request was successful (status code 200)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Render JavaScript by calling render() method\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Save the fully rendered HTML content to a file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.html\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests_html.py:586\u001b[0m, in \u001b[0;36mHTML.render\u001b[0;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, script: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, wait: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, scrolldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sleep: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, timeout: Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8.0\u001b[39m, keep_page: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    with an updated version, with JavaScript executed.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    Chromium into your home directory (``~/.pyppeteer``).\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mbrowser  \u001b[38;5;66;03m# Automatically create a event loop and browser\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# Automatically set Reload to False, if example URL is being used.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests_html.py:729\u001b[0m, in \u001b[0;36mHTMLSession.browser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 729\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbrowser)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "# URL of the webpage containing the JavaScript\n",
    "url = 'https://www.myneta.info/LokSabha2024/index.php?action=show_candidates&constituency_id=205'\n",
    "\n",
    "# Create an HTMLSession object\n",
    "session = HTMLSession()\n",
    "\n",
    "# Use the HTMLSession object to get the content\n",
    "response = session.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Render JavaScript by calling render() method\n",
    "    response.html.render()\n",
    "\n",
    "    # Save the fully rendered HTML content to a file\n",
    "    with open('output.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(response.html.html)\n",
    "    print(\"Content saved successfully!\")\n",
    "else:\n",
    "    print(\"Failed to fetch content. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8273d9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.myneta.info/LokSabha2024/index.php?action=show_candidates&constituency_id=205\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#url = 'YOUR_URL_HERE'\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Run the asynchronous function in the event loop\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun(fetch_and_save_content(url))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "import asyncio\n",
    "\n",
    "async def fetch_and_save_content(url):\n",
    "    # Create an AsyncHTMLSession object\n",
    "    session = AsyncHTMLSession()\n",
    "\n",
    "    # Use the AsyncHTMLSession object to get the content\n",
    "    response = await session.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Render JavaScript by calling render() method\n",
    "        await response.html.arender()\n",
    "\n",
    "        # Save the fully rendered HTML content to a file\n",
    "        with open('output.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(response.html.html)\n",
    "        print(\"Content saved successfully!\")\n",
    "    else:\n",
    "        print(\"Failed to fetch content. Status code:\", response.status_code)\n",
    "\n",
    "    # Close the session\n",
    "    await session.close()\n",
    "\n",
    "# URL of the webpage containing the JavaScript\n",
    "#url = 'YOUR_URL_HERE'\n",
    "\n",
    "# Run the asynchronous function in the event loop\n",
    "asyncio.run(fetch_and_save_content(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92e39e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Run the asynchronous function in the event loop\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(fetch_and_save_content(url))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Close the event loop\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loop\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/base_events.py:629\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_running()\n\u001b[1;32m    631\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    632\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "from requests_html import AsyncHTMLSession\n",
    "import asyncio\n",
    "\n",
    "async def fetch_and_save_content(url):\n",
    "    # Create an AsyncHTMLSession object\n",
    "    session = AsyncHTMLSession()\n",
    "\n",
    "    # Use the AsyncHTMLSession object to get the content\n",
    "    response = await session.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Render JavaScript by calling render() method\n",
    "        await response.html.arender()\n",
    "\n",
    "        # Save the fully rendered HTML content to a file\n",
    "        with open('output.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(response.html.html)\n",
    "        print(\"Content saved successfully!\")\n",
    "    else:\n",
    "        print(\"Failed to fetch content. Status code:\", response.status_code)\n",
    "\n",
    "    # Close the session\n",
    "    await session.close()\n",
    "\n",
    "# URL of the webpage containing the JavaScript\n",
    "url = 'https://www.myneta.info/LokSabha2024/index.php?action=show_candidates&constituency_id=205'\n",
    "\n",
    "# Create an event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# Run the asynchronous function in the event loop\n",
    "loop.run_until_complete(fetch_and_save_content(url))\n",
    "\n",
    "# Close the event loop\n",
    "loop.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb68247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e5f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f6613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c7737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f5efa2",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6740bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Get all files in the current directory\n",
    "files = os.listdir('/Users/saml16/projects/Elections_info/static/lok_sabha_2024/phase_1/constituency_html_dump/')\n",
    "\n",
    "# Filter out the files that end with .html and remove the .html extension\n",
    "html_files = [f[:-5] for f in files if f.endswith('.html')]\n",
    "\n",
    "# Write the file names to a new file\n",
    "with open('/Users/saml16/projects/Elections_info/static/lok_sabha_2024/constituency_list.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"constituency_ids\"])\n",
    "    for name in html_files:\n",
    "        writer.writerow([name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa639da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv(constituency_links_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f5cbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constituency</th>\n",
       "      <th>constituency_link</th>\n",
       "      <th>state</th>\n",
       "      <th>constituency_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARUNACHAL EAST</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ARUNACHAL PRADESH</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARUNACHAL WEST</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ARUNACHAL PRADESH</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DARRANG-UDALGURI</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIBRUGARH</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>ASSAM</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>BALURGHAT</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>COOCH BEHAR (SC)</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>DARJEELING</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>JALPAIGURI (SC)</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>RAIGANJ</td>\n",
       "      <td>index.php?action=show_candidates&amp;constituency_...</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    constituency  \\\n",
       "0    ANDAMAN AND NICOBAR ISLANDS   \n",
       "1                 ARUNACHAL EAST   \n",
       "2                 ARUNACHAL WEST   \n",
       "3               DARRANG-UDALGURI   \n",
       "4                      DIBRUGARH   \n",
       "..                           ...   \n",
       "184                    BALURGHAT   \n",
       "185             COOCH BEHAR (SC)   \n",
       "186                   DARJEELING   \n",
       "187              JALPAIGURI (SC)   \n",
       "188                      RAIGANJ   \n",
       "\n",
       "                                     constituency_link  \\\n",
       "0    index.php?action=show_candidates&constituency_...   \n",
       "1    index.php?action=show_candidates&constituency_...   \n",
       "2    index.php?action=show_candidates&constituency_...   \n",
       "3    index.php?action=show_candidates&constituency_...   \n",
       "4    index.php?action=show_candidates&constituency_...   \n",
       "..                                                 ...   \n",
       "184  index.php?action=show_candidates&constituency_...   \n",
       "185  index.php?action=show_candidates&constituency_...   \n",
       "186  index.php?action=show_candidates&constituency_...   \n",
       "187  index.php?action=show_candidates&constituency_...   \n",
       "188  index.php?action=show_candidates&constituency_...   \n",
       "\n",
       "                           state  constituency_id  \n",
       "0    ANDAMAN AND NICOBAR ISLANDS              579  \n",
       "1              ARUNACHAL PRADESH               29  \n",
       "2              ARUNACHAL PRADESH               28  \n",
       "3                          ASSAM               35  \n",
       "4                          ASSAM               33  \n",
       "..                           ...              ...  \n",
       "184                  WEST BENGAL              539  \n",
       "185                  WEST BENGAL              534  \n",
       "186                  WEST BENGAL              537  \n",
       "187                  WEST BENGAL              536  \n",
       "188                  WEST BENGAL              538  \n",
       "\n",
       "[189 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65332cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/04/4d/a6e8afd65b87372e275eb612d564ec68f79195e9b7e27004a3b2cce69686/selenium-4.20.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.20.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/17/c9/f86f89f14d52f9f2f652ce24cb2f60141a51d087db1563f3fba94ba07346/trio-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from selenium) (2024.2.2)\n",
      "Collecting typing_extensions>=4.9.0 (from selenium)\n",
      "  Obtaining dependency information for typing_extensions>=4.9.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for attrs>=23.2.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in /Users/saml16/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/saml16/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for sniffio>=1.3.0 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for wsproto>=0.14 from https://files.pythonhosted.org/packages/78/58/e860788190eba3bcce367f74d29c4675466ce8dddfba85f7827588416f01/wsproto-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/saml16/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Obtaining dependency information for h11<1,>=0.9.0 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.20.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing_extensions, sniffio, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Uninstalling attrs-22.1.0:\n",
      "      Successfully uninstalled attrs-22.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.34.68 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-23.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.20.0 sniffio-1.3.1 trio-0.25.0 trio-websocket-0.11.1 typing_extensions-4.11.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "789c32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# Set up the webdriver\n",
    "driver = webdriver.Firefox()  # or webdriver.Chrome(), depending on your browser\n",
    "\n",
    "# Open the HTML file\n",
    "driver.get(\"https://www.myneta.info/LokSabha2024/index.php?action=show_candidates&constituency_id=186\")\n",
    "\n",
    "# Save the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Write the page source to a new HTML file\n",
    "with open(\"output.html\", \"w\") as f:\n",
    "    f.write(page_source)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
